{
 "metadata": {
  "name": "",
  "signature": "sha256:91468d9c607014e100bf4a0e081791860e57563c0b0233a98c3cf3ddf8b027b3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "%load_ext vimception"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from IPython.core.debugger import Tracer\n",
      "import matplotlib.pyplot as plt\n",
      "from copy import deepcopy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ExpParam:\n",
      "    def __init__(self,\n",
      "                 NNets = 5, InSize = 12, noPlots = 0,\n",
      "                 washoutLength = 100, learnLength = 1000,\n",
      "                 COinitLength = 1000, COadaptLength = 2000,\n",
      "                 testLength = 1000, TychWouts = 0.05,\n",
      "                 LRR = 0.005, # leaking rate for R estimation\n",
      "                 delta = 0,   # timesteps delayed predictions\n",
      "                 apertures = np.Inf, # Inf if no conceptors are to be inserted\n",
      "                 showNets = [], # which nets are to be diagnostic-plotted\n",
      "                 mismatchExp = 1,\n",
      "                 signalPlotLength = 40, plotN = 8, maxLag = 49):\n",
      "        # Experiment control params\n",
      "        self.NNets = NNets\n",
      "        self.noPlots = noPlots\n",
      "        self.InSize = InSize\n",
      "        self.TychWouts = TychWouts, # regularizers for Wout\n",
      "        self.COinitLength = COinitLength\n",
      "        self.COadaptLength = COadaptLength\n",
      "        self.testLength = testLength\n",
      "        self.LRR = LRR\n",
      "        self.delta = delta\n",
      "        self.apertures = apertures\n",
      "        self.mismatchExp = mismatchExp # a value of 1/2 would be mathematically indicated\n",
      "                                  # larger, over-compensating values work better\n",
      "\n",
      "        self.washoutLength = washoutLength\n",
      "        self.learnLength = learnLength\n",
      "        \n",
      "        # plotting specs\n",
      "        self.showNets = [0, 2, NNets-1]\n",
      "        self.signalPlotLength = signalPlotLength\n",
      "        self.plotN = plotN\n",
      "        self.maxLag = maxLag\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Reservoir:\n",
      "    def __init__(self,\n",
      "                 InSize = 12,\n",
      "                 N = 200,  # network size\n",
      "                 Nfb = 2, # number of feedbacks\n",
      "                 SR = 1 ,  # spectral radius\n",
      "                 WinScaling = .4 ,\n",
      "                 WfbScaling = 0. ,\n",
      "                 BiasScaling = 0.):\n",
      "\n",
      "        self.InSize = InSize\n",
      "        #showNets = showNets\n",
      "        self.N = N\n",
      "        self.Nfb = Nfb\n",
      "        self.SR = SR\n",
      "        self.WinScaling = WinScaling\n",
      "        self.WfbScaling = WfbScaling\n",
      "        self.BiasScaling = BiasScaling\n",
      "        \n",
      "        self.initialize_system()\n",
      "\n",
      "    def initialize_system(self):\n",
      "        np.random.seed(100) # ALL RES created are THE SAME\n",
      "        # Create raw weights\n",
      "        WinRaw = np.random.randn(self.N, self.InSize);\n",
      "        #WfbRaw = np.random.randn(self.N, self.Nfb);\n",
      "        biasRaw = np.random.randn(self.N, 1);\n",
      "        \n",
      "        WRaw = np.random.randn(self.N, self.N)\n",
      "        specrad = max(np.abs(np.linalg.eig(WRaw)[0]))\n",
      "        WRaw = WRaw / specrad\n",
      "#         FRaw = np.random.randn(self.M,self.N);\n",
      "#         FRawRowNorms = np.sqrt(np.sum(FRaw ** 2, 1));\n",
      "#         FRaw = np.dot(np.diag(1 / FRawRowNorms), FRaw)\n",
      "#         GstarRaw = np.random.randn(self.N,self.M);\n",
      "#         GF = np.dot(GstarRaw, FRaw);\n",
      "#         specrad = max(np.abs(np.linalg.eig(GF)[0]));\n",
      "#         FstarRaw = FRaw;\n",
      "#         GstarRaw = GstarRaw / specrad;\n",
      "\n",
      "        # Scale raw weights and initialize weights\n",
      "#         self.F    = FstarRaw;\n",
      "#         self.G    = GstarRaw * self.SR;\n",
      "        self.W = WRaw * self.SR\n",
      "        self.Win  = self.WinScaling * WinRaw;\n",
      "#         self.Wfb  = self.WfbScaling * WfbRaw;\n",
      "        self.bias = self.BiasScaling * biasRaw;\n",
      "\n",
      "        self.x = np.zeros((self.N, 1), dtype=float)\n",
      "#         self.r = np.zeros((self.N, 1), dtype=float)\n",
      "#         self.z = np.zeros((self.M, 1), dtype=float)\n",
      "        \n",
      "    def update_state(self, in_patt, conceptor=None):\n",
      "        if in_patt.shape[0] != self.InSize:\n",
      "#             print self.InSize, in_patt.shape[0]\n",
      "            raise ValueError(\"Input size is incorrect\")\n",
      "    \n",
      "        self.x = np.tanh((np.dot(self.W, self.x)) + np.dot(self.Win, in_patt).reshape((self.N, 1)) + self.bias)\n",
      "\n",
      "#         print np.dot(self.Win, in_patt).reshape((50,1))\n",
      "#         self.r = np.tanh(np.dot(self.G, self.z) + np.dot(self.Win, in_patt).reshape((self.N, 1)) + self.bias)\n",
      "#         self.z = np.dot(self.F, self.r)\n",
      "        if conceptor is not None:\n",
      "            self.x = np.reshape(conceptor,(self.N, 1)) * self.x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_data(dataType = 1, p = ExpParam()):\n",
      "    # filter function.\n",
      "    # 1: NARMA data with NARMA coefficient filtering\n",
      "    # 2: rand data with shift, scale, exponentiation\n",
      "\n",
      "    L = p.washoutLength + p.COinitLength + p.COadaptLength + p.learnLength;\n",
      "    trainPatt = []; testPatt = []; testPattProto = [];\n",
      "    \n",
      "    if dataType == 0:\n",
      "        Filter = lambda y, ym1, ym2, a, b, c, d: np.tanh( a * y + b *\\\n",
      "                            (ym1) + c * (ym2) * (ym1) + d *(np.random.randn(1)))\n",
      "        filterWashout = 100;\n",
      "        \n",
      "        baselineParams = [2, -1, -2, 0];\n",
      "        pattScaling = 1; pattShift = 1;\n",
      "    \n",
      "    if dataType == 1:\n",
      "        Filter = lambda y, ym1, ym2, a, b, c, d: np.tanh( a * y + b *\\\n",
      "                                    (ym1) + c * (ym2) * (ym1) + d *(np.random.randn(1)))\n",
      "        filterWashout = 100;\n",
      "        \n",
      "        baselineParams = [2, -1, -2, 0];\n",
      "        pattScaling = 1; pattShift = 1;\n",
      "        \n",
      "    elif dataType == 2:\n",
      "        Filter = lambda y, a, b, c: a + b * (sign(y) * abs(y) ** c);\n",
      "        filterWashout = 100;\n",
      "        baselineParams = [-2, .5, 1];\n",
      "\n",
      "    if dataType == 0:\n",
      "        trainPatt = np.array([0.5 * (sin(2 * pi * i / 5)) for i in range(L)])\n",
      "    elif dataType == 1:\n",
      "        trainPatt = np.array([0.5 * (sin(2 * pi * i / 8) + sin(2 * pi * i / 5.03)) for i in range(L)])\n",
      "    \n",
      "    \n",
      "    if dataType == 0 or dataType == 1:\n",
      "        a = baselineParams[0];\n",
      "        b = baselineParams[1];\n",
      "        c = baselineParams[2];\n",
      "        d = baselineParams[3];\n",
      "        testPatt = trainPatt.copy();\n",
      "        for n in xrange(2, L):\n",
      "            testPatt[n] = Filter(testPatt[n],testPatt[n-1],testPatt[n-2],\n",
      "                                  a, b, c, d);\n",
      "        \n",
      "        testPatt = pattScaling * testPatt + pattShift\n",
      "    \n",
      "        trainPatt = np.reshape(trainPatt, (1, L))\n",
      "        testPatt = np.reshape(testPatt, (1, L))\n",
      "        testPattProto = trainPatt;    \n",
      "        \n",
      "    elif dataType == 2:\n",
      "        trainPatt = rand(1, L);\n",
      "        a = baselineParams[0];\n",
      "        b = baselineParams[1];\n",
      "        c = baselineParams[2];\n",
      "        testPattProto = trainPatt;\n",
      "\n",
      "        testPatt = trainPatt.copy();\n",
      "        for n in xrange(L):\n",
      "            testPatt[n] = Filter(trainPatt[n], a, b, c);\n",
      "            \n",
      "    return trainPatt, testPatt, testPattProto"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rmse(patt1, patt2):\n",
      "    err = patt1 - patt2\n",
      "    return np.sqrt(np.mean(err ** 2, axis=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def nrmse(patt1, patt2):\n",
      "    err = patt1 - patt2\n",
      "    combinedVar = 0.5 * (np.var(patt1, axis=1, ddof=1) + np.var(patt2, axis=1, ddof=1))\n",
      "    return np.sqrt(np.mean(err ** 2, axis=1) / combinedVar)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "def autocorr(patt, maxLag):\n",
      "    # Returns autocorrs for a scalar series on lags 1, 2 ... maxLag\n",
      "    # input must be a numpy array in either column or row format\n",
      "    \n",
      "    if len(patt) <= maxLag\n",
      "        raise ValueError('timeseries too short for computing requested autocorrs')\n",
      "\n",
      "    # get the timeseries in col form\n",
      "    if patt.shape[0] == 1:\n",
      "        patt = np.transpose(patt)\n",
      "        \n",
      "    L = patt.shape[0]\n",
      "    \n",
      "    dataLagMat = np.zeros((L-maxLag, maxLag+1))\n",
      "    dataLagMat[:,0] = patt[0:L-maxLag, 0]\n",
      "    tsCol(1:L-maxLag,1)\n",
      "    \n",
      "    for lag = 1:maxLag\n",
      "        dataLagMat(:,lag+1) = tsCol(1+lag:L-maxLag+lag, 1);\n",
      "    \n",
      "    dataMat = repmat(tsCol(1:L-maxLag,1),1, maxLag+1);\n",
      "    \n",
      "    autocorrPlotData = diag(dataLagMat' * dataMat) / (L-maxLag);"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_eq(trainPatt, res = None, param = ExpParam()):\n",
      "    \n",
      "    param.InSize = trainPatt.shape[0]\n",
      "    if res is None:\n",
      "        print \"Generating new reservoir\"\n",
      "        res = Reservoir(InSize=trainPatt.shape[0])\n",
      "    ####################################################################################################\n",
      "    # 2-module modeling - Compute Conceptor\n",
      "    print \"Learning Conceptor...\"\n",
      "    \n",
      "    xCollector = np.zeros((res.N, param.learnLength))\n",
      "\n",
      "    for n in xrange(param.washoutLength + param.learnLength):\n",
      "        res.update_state(trainPatt[:, n]) \n",
      "\n",
      "        if n >= param.washoutLength:\n",
      "            xCollector[:, n - param.washoutLength] = res.x[:, 0];\n",
      "    \n",
      "    R = np.diag(np.dot(xCollector, np.transpose(xCollector))) / param.learnLength;\n",
      "    \n",
      "    if param.apertures == np.Inf:\n",
      "        C = np.ones(R.shape, dtype=float)\n",
      "    else:\n",
      "        C = R / (R + param.apertures**(-2));\n",
      "#         U, E, V = np.linalg.svd(R);    # TRY THIS WAY!\n",
      "#         S = np.dot(E, np.linalg.pinv(E + param.apertures ** (-2) * np.eye(E.shape[0])))\n",
      "#         C = np.dot(np.dot(U, S), np.transpose(U))\n",
      "    ####################################################################################################\n",
      "    ## Learn Rref,  Wout, and collect r state plot data\n",
      "    print \"Learning Rref, Wout...\"\n",
      "    \n",
      "    xCollector = np.zeros((res.N, param.learnLength))\n",
      "    pCollector = np.zeros((res.InSize, param.learnLength))\n",
      "    predCollector = np.zeros((res.InSize, param.learnLength))\n",
      "    \n",
      "    # Here we are doing the same thing, but restricting the dynamics using learnt conceptor\n",
      "    for n in xrange(param.delta, param.washoutLength + param.learnLength):\n",
      "        res.update_state(trainPatt[:, n], conceptor=C)\n",
      "        \n",
      "        if n >= param.washoutLength:\n",
      "            xCollector[:, n - param.washoutLength] = res.x[:, 0]\n",
      "            pCollector[:, n - param.washoutLength] = trainPatt[:, n - param.delta]\n",
      "            predCollector[:, n - param.washoutLength] = trainPatt[:, n+1 - param.delta]\n",
      "\n",
      "\n",
      "    # Reference R - represents E[z^2] for the ideal case\n",
      "    Rref = np.diag(np.dot(xCollector, np.transpose(xCollector))) / param.learnLength;\n",
      "    args = xCollector\n",
      "    targs = pCollector\n",
      "    # Note that WoutAll learns to predict y(n-delta) not y(n)\n",
      "    WoutAll = np.transpose(np.dot(np.linalg.pinv(np.dot(args, np.transpose(args)) / param.learnLength + \\\n",
      "                                                 param.TychWouts[0] * np.eye(res.N)\n",
      "                                                 ),\n",
      "                                  np.dot(args, np.transpose(targs)) / param.learnLength\n",
      "                                  )\n",
      "                           )\n",
      "\n",
      "    ytrainNRMSE = nrmse(np.dot(WoutAll, args), targs)\n",
      "    print('Training NRMSE: %f' % np.mean(ytrainNRMSE))\n",
      "    \n",
      "    return Rref, C, WoutAll#, ytrainNRMSE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing\n",
      "def test_eq(Rref, C, WoutAll,\n",
      "            testPattProto,\n",
      "            testPatt,\n",
      "            param = ExpParam(),\n",
      "            resProto = None,):\n",
      "    \n",
      "    param.InSize = testPatt.shape[0]\n",
      "    if param.InSize != WoutAll.shape[0]:\n",
      "        raise TypeError(\"Shape mismatch - WoutAll: \" + str(WoutAll.shape[0]) + \" , InSize: \" + str(param.InSize))\n",
      "    ####################################################################################################\n",
      "    print \"Washout...\"\n",
      "    \n",
      "    if resProto is None:\n",
      "        resProto = Reservoir(InSize=param.InSize)\n",
      "    \n",
      "    res = [deepcopy(resProto) for i in xrange(param.NNets)]     # create NNets reservoirs using prototype\n",
      "\n",
      "    yCollectortest = np.zeros((param.NNets, param.InSize, param.testLength))   # Test Output from each net\n",
      "    pCollectortest = np.zeros((param.InSize, param.testLength));\n",
      "    uCollectortest = np.zeros((param.InSize, param.testLength));\n",
      "    yAll = np.zeros((param.NNets, res[0].InSize,1))\n",
      "\n",
      "    for n in xrange(param.washoutLength):             # just the WASHOUT period\n",
      "        res[0].update_state(testPatt[:, n], C)\n",
      "        yAll[0] = np.dot(WoutAll, res[0].x)\n",
      "\n",
      "        for nNet in xrange(1, param.NNets):                              # For subsequent cascades\n",
      "            res[nNet].update_state(yAll[nNet-1], C)\n",
      "            yAll[nNet] = np.dot(WoutAll, res[nNet].x)\n",
      "\n",
      "    Rref = np.reshape(Rref, (res[0].N, 1))\n",
      "    ####################################################################################################\n",
      "    # Initialize the average (expected) signal energy vector E[z.^2], called\n",
      "    # Ezsqr, for all nets in the cascade,\n",
      "    # by driving the cascade for COinitLength steps with input signal\n",
      "    print \"Initialize Ezsqr...\"\n",
      "    \n",
      "    shift = param.washoutLength\n",
      "    MismatchRatios = []; zColl = []; Ezsqr = [];\n",
      "    for nNet in xrange(param.NNets):\n",
      "        zColl.append(np.zeros((res[nNet].N, param.COinitLength)))\n",
      "#         Ezsqr.append(np.zeros((res[nNet].N, 1)))\n",
      "        MismatchRatios.append(np.zeros((res[i].N, 1)))            # Test MR for each net\n",
      "  \n",
      "    for n in xrange(param.COinitLength):\n",
      "        res[0].update_state(testPatt[:, n+shift], C)\n",
      "        yAll[0] = np.dot(WoutAll, res[0].x)\n",
      "        zColl[0][:, n] = res[0].x[:, 0];\n",
      "\n",
      "        for nNet in xrange(1, param.NNets):                       # For subsequent cascades\n",
      "            res[nNet].update_state(yAll[nNet-1], C)\n",
      "            yAll[nNet] = np.dot(WoutAll, res[nNet].x)\n",
      "            zColl[nNet][:, n] = res[nNet].x[:, 0];\n",
      "        \n",
      "    for nNet in xrange(param.NNets):\n",
      "        Ezsqr.append(np.diag(np.dot(zColl[nNet], np.transpose(zColl[nNet]))) / param.COinitLength)\n",
      "        Ezsqr[nNet] = np.reshape(Ezsqr[nNet], (res[nNet].N, 1))\n",
      "        # the mismatch ratios will function as the \"ERROR\" term that is used to pull\n",
      "        # the actual signal energies of the z vectors toward the reference z\n",
      "        # vectors known from the \"clean\" training input\n",
      "        MismatchRatios[nNet] = (Rref / Ezsqr[nNet]) ** param.mismatchExp;\n",
      "\n",
      "#     print ', '.join(map(str, [np.mean(MismatchRatios[i]) for i in range(param.NNets)]))\n",
      "    ####################################################################################################\n",
      "    ## Adapt forward through nets for COadaptLength\n",
      "    print \"Adapting MismatchRatio...\"\n",
      "    \n",
      "    shift = param.washoutLength + param.COinitLength;\n",
      "#     y_co_adapt = np.zeros((param.InSize, param.COadaptLength))\n",
      "\n",
      "    for n in xrange(param.COadaptLength):\n",
      "        res[0].update_state(testPatt[:, n+shift], C)\n",
      "        # in the next two lines, the core adaptation is done, by re-shaping the\n",
      "        # z vector with the help of the mismatch ratios which pull it toward\n",
      "        # the reference z signal energy profile known from training\n",
      "        yAll[0] = np.dot(WoutAll, MismatchRatios[0] * res[0].x)\n",
      "\n",
      "        for nNet in xrange(1, param.NNets):                              # For subsequent cascades\n",
      "            res[nNet].update_state(yAll[nNet-1], C)\n",
      "            yAll[nNet] = np.dot(WoutAll, MismatchRatios[nNet] * res[nNet].x)\n",
      "\n",
      "        # the following updates the estimate of Ezsqr and the mismatch ratio\n",
      "        for nNet in xrange(param.NNets):\n",
      "            Ezsqr[nNet] = (1-param.LRR) * Ezsqr[nNet] + param.LRR * res[nNet].x ** 2;\n",
      "            MismatchRatios[nNet] = (Rref / Ezsqr[nNet]) ** param.mismatchExp;\n",
      "\n",
      "#         y_co_adapt[:, n] = yAll[param.NNets - 1][:, 0]\n",
      "        \n",
      "#     if param.noPlots == False:\n",
      "#         plt.figure();\n",
      "#         xs = range(param.COadaptLength - 100, param.COadaptLength)\n",
      "#         plt.plot([y_co_adapt[0, i] for i in xs], 'b', linewidth=1.5);\n",
      "#         plt.plot([trainPatt[0, shift+i] for i in xs], 'r', linewidth= 1.5);\n",
      "#         plt.title('y[0] during COadapt vs trainPatt (red)');\n",
      "    \n",
      "    ####################################################################################################  \n",
      "    ## Finally, stop adapting, stay in the last adapted configuaration\n",
      "    # and collect data for plotting and error diagnostics\n",
      "    print \"Testing...\"\n",
      "    \n",
      "    shift = param.washoutLength + param.COinitLength + param.COadaptLength;\n",
      "    \n",
      "    for n in xrange(param.testLength):\n",
      "        u = testPatt[:, n + shift]\n",
      "        res[0].update_state(u, C)\n",
      "        yAll[0] = np.dot(WoutAll, MismatchRatios[0] * res[0].x)\n",
      "        yCollectortest[0][:, n] = yAll[0][:, 0]\n",
      "\n",
      "        for nNet in xrange(1, param.NNets):                              # For subsequent cascades\n",
      "            res[nNet].update_state(yAll[nNet-1], C)\n",
      "            yAll[nNet] = np.dot(WoutAll, MismatchRatios[nNet] * res[nNet].x)\n",
      "            yCollectortest[nNet][:, n] = yAll[nNet][:, 0]\n",
      "        \n",
      "        pCollectortest[:,n] = testPattProto[:, n + shift - param.NNets * param.delta]\n",
      "        uCollectortest[:,n] = testPatt[:, n + shift - param.NNets * param.delta]\n",
      "\n",
      "    ####################################################################################################  \n",
      "    # Calculate errors\n",
      "    print \"Calculating Errors...\"\n",
      "    ytestNRMSE = []; EngyRatios = []; energyErrs = []; autoCorry = [];\n",
      "    \n",
      "    rawNRMSE = nrmse(testPattProto, testPatt)\n",
      "#     autoCorrP = autocorr(pCollectortest, maxLag)\n",
      "\n",
      "    for nNet in xrange(param.NNets):\n",
      "        ytestNRMSE.append(nrmse(yCollectortest[nNet], pCollectortest)[0])\n",
      "        EngyRatios.append(Rref / Ezsqr[nNet])\n",
      "#         autoCorry.append(autocorr(yCollectortest[nNet], maxLag))\n",
      "        energyErrs.append(np.linalg.norm((Rref - Ezsqr[nNet]) / np.linalg.norm(Rref)) ** 2)\n",
      "    \n",
      "    print '-' * 20\n",
      "    print('raw NRMSE = %0.3g' %  (np.mean(rawNRMSE)));\n",
      "    print('meanabs Wout = %0.3g' %  np.mean(abs(WoutAll)));\n",
      "    print('test  NRMSEs = %s' % ', '.join(map(str, ytestNRMSE)))\n",
      "    print('energyErrs = %s' % ', '.join(map(str, energyErrs)))\n",
      "#     print('autoCorrErrs = %0.3g' % autoCorrErrs);\n",
      "\n",
      "    ####################################################################################################  \n",
      "    ## Plots\n",
      "\n",
      "    if param.noPlots == 0:\n",
      "#         # Autocorrelations\n",
      "#         for nNet in param.showNets:\n",
      "#             figNr = figNr + 1;\n",
      "#             plt.figure(figNr); clf;\n",
      "#             hold('on')\n",
      "#             plot(autoCorrP, 'r', 'LineWidth',2);\n",
      "#             plot(autoCorry{nNet}, 'b', 'LineWidth',2);\n",
      "#             hold off;\n",
      "#             title(sprintf('Autocorrs in #g (r=orig)', nNet));\n",
      "#\n",
      "        # Signals\n",
      "        maxy = -10; miny = 10; \n",
      "        raws = []; targets = []; effectives = [];\n",
      "        for nNet in xrange(param.NNets):\n",
      "            raws.append(uCollectortest[0, - param.signalPlotLength + 1 : ])\n",
      "            plt.maxy = max(maxy, max(raws[nNet]));\n",
      "            plt.miny = min(miny, min(raws[nNet]));\n",
      "            targets.append(pCollectortest[0, - param.signalPlotLength + 1 : ])\n",
      "            plt.maxy = max(maxy, max(targets[nNet]));\n",
      "            plt.miny = min(miny, min(targets[nNet]));\n",
      "            effectives.append(yCollectortest[nNet][0, - param.signalPlotLength + 1 : ])\n",
      "            plt.maxy = max(maxy, max(effectives[nNet]));\n",
      "            plt.miny = min(miny, min(effectives[nNet]));\n",
      "\n",
      "        for nNet in param.showNets:\n",
      "            plt.figure()\n",
      "            plt.plot(raws[nNet], color='0.75', linewidth=3)\n",
      "            plt.plot(targets[nNet], 'r', linewidth=2)\n",
      "            plt.plot(effectives[nNet], 'b', linewidth=2, alpha=0.75)\n",
      "\n",
      "            #set(gca, 'YLim',[miny-0.2 maxy+0.2], 'XLim', [1 signalPlotLength]); # why?\n",
      "            plt.title('y' + str(nNet) + 'test out vs target (r)');\n",
      "\n",
      "        # Energy Ratios\n",
      "        for nNet in param.showNets:\n",
      "            plt.figure()\n",
      "            plt.plot(EngyRatios[nNet]);\n",
      "            plt.title('Energy ratios (unsorted) in ' + str(nNet));\n",
      "\n",
      "        # Energy error and autocorr error plot\n",
      "        plt.figure();\n",
      "        plt.plot(np.log10(energyErrs),'bx-', linewidth=2);\n",
      "#         plot(np.log10(autoCorrErrs),'gx-', linewidth=2);\n",
      "        plt.title('log10 energyErrs(b) autoCErrs(g)');\n",
      "    \n",
      "    return yCollectortest[param.NNets - 1], pCollectortest, \\\n",
      "           uCollectortest, ytestNRMSE, energyErrs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "%pylab inline\n",
      "exp = ExpParam()\n",
      "train1, test1, testProto1 = generate_data()\n",
      "r2, c2, w2 = train_eq(train1, param=exp)\n",
      "test_eq(r2, c2, w2, testProto1, test1, param=exp);"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}